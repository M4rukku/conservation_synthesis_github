{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Markus\\\\Documents\\\\Cambridge_Projects\\\\GroupProject\\\\conservation_synthesis'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#Ensure we are at the base level \n",
    "os.chdir(\"../\")\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sources.data_processing.repositories import CrossrefRepository, OpenAireRepository, CoreRepository, AbstractRepository\n",
    "from sources.data_processing.queries import ArticleMetadata, Response, KeywordQuery\n",
    "from data.cleancsv import CleanCSV\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "import json\n",
    "import pathlib\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Markus\\\\Documents\\\\Cambridge_Projects\\\\GroupProject\\\\conservation_synthesis'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "repo = CoreRepository().__class__ #Insert your Repo here\n",
    "data = CleanCSV(\"data/cleaned_references.csv\")\n",
    "responses = []\n",
    "all_entries = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def batch_data(repo, start_index, max_index):\n",
    "    batch_size = repo().max_queries_per_second\n",
    "    cur_index = start_index\n",
    "    while cur_index<max_index:\n",
    "        yield range(cur_index, min(cur_index+batch_size, max_index))\n",
    "        cur_index += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_kwd_query_from_row(data_row):\n",
    "    return KeywordQuery(query_id=0, \n",
    "                        authors = \n",
    "                            data_row.authors if len(data_row.authors) > 0 else None, \n",
    "                        title = data_row.title, \n",
    "                        journal_name = data_row.pub_title if data_row.pub_title!=\"\" else None, \n",
    "                        doi = data_row.doi if data_row.doi!=\"\" else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "async def process_data(repo, data, start=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(data)\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for _range in batch_data(repo, start, end):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            _queries = [get_kwd_query_from_row(data[i]) for i in _range]\n",
    "            _repos = [repo() for i in _range]\n",
    "            \n",
    "            response = await asyncio.gather(\n",
    "                *[_repo.execute_query(_query, session) \n",
    "                    for _repo, _query in zip(_repos, _queries)], \n",
    "                return_exceptions=True)\n",
    "            \n",
    "            response = [(i, resp.metadata.as_dict()) \n",
    "                            for i, resp in zip(_range, response) \n",
    "                                if not isinstance(resp, Exception)]\n",
    "            \n",
    "            for i, rmeta in response:\n",
    "                rmeta[\"index\"] = i\n",
    "                responses.append(rmeta)\n",
    "\n",
    "            time_taken = start_time - time.time() #Number of seconds that passed\n",
    "            if time_taken>=1:\n",
    "                continue\n",
    "            else:\n",
    "                time.sleep(1-time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Process Data in Batches of 1000\n",
    "start_ind = 0\n",
    "end_ind = len(data)\n",
    "step = 1000\n",
    "\n",
    "data_dir = pathlib.Path('.') / \"data\" / f\"clean_references_{repo().get_identifier()}\"\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "while start_ind < end_ind:\n",
    "    next_end_ind = min(start_ind + step, end_ind)\n",
    "    await process_data(repo, data, start_ind, next_end_ind)\n",
    "    \n",
    "    write_path = data_dir / f\"{repo().get_identifier()}_cr_{start_ind}_{next_end_ind}\"\n",
    "    with write_path.open(\"w\") as f:\n",
    "        json.dump(responses, f)\n",
    "    \n",
    "    start_ind += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "all_files = [file_path for file_path in data_dir.iterdir()]\n",
    "for file_path in all_files:\n",
    "    with file_path.open(\"r\") as f:\n",
    "        all_data.append(json.load(f))\n",
    "\n",
    "merged_dicts = list(chain.from_iterable(all_data))\n",
    "write_path = data_dir / f\"{repo().get_identifier()}_merged\"\n",
    "with write_path.open(\"w\") as f:\n",
    "    json.dump(merged_dicts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###############CLEANUP -- Remove all files, but the merged one\n",
    "for file_path in all_files: \n",
    "    file_path.unlink()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
